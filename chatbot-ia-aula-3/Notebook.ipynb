{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e857e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if entrada_usuario.lower() in [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\"]:\n",
    "    print(\"Assistente IA: Entendido! Só um momento enquanto gero o resumo...\")\n",
    "\n",
    "    prompt_extracao = \"\"\"\n",
    "    Analise o histórico da conversa e extraia um JSON com:\n",
    "    1. intencao (VENDAS, SUPORTE, RH)\n",
    "    2. nome_cliente\n",
    "    3. email_cliente\n",
    "    4. resumo_solicitacao\n",
    "    Responda APENAS o JSON.\n",
    "    \"\"\"\n",
    "    contexto_extracao = contexto + [{'role': 'user', 'content': prompt_extracao}]\n",
    "\n",
    "    resposta_json = get_completion_from_messages(\n",
    "        contexto_extracao, \n",
    "        json_mode=True, \n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    nome_arquivo = f\"lead_{timestamp}.json\"\n",
    "\n",
    "    try:\n",
    "        with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "            f.write(resposta_json)\n",
    "        print(f\"\\n[SISTEMA]: Lead salvo com sucesso em '{nome_arquivo}'!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[SISTEMA]: Erro ao salvar arquivo: {e}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot v2\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        entrada_usuario = input(\"Você: \")\n",
    "        if entrada_usuario.lower() in [\"sair\", \"tchau\", \"exit\"]:\n",
    "            print(\"Assistente IA: Entendido. Tenha um ótimo dia!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78947b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot v3\n",
    "while True:\n",
    "    try:\n",
    "        entrada_usuario = input(\"Você: \")\n",
    "        palavras_saida = [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\"]\n",
    "        if any(palavra in entrada_usuario.lower() for palavra in palavras_saida):\n",
    "            print(\"Assistente IA: Entendido! Gerando o resumo do atendimento...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72c2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3982d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciar_chat():\n",
    "\n",
    "    contexto = [{'role': 'system', 'content': system_prompt_central_v2}]\n",
    "    \n",
    "    print(\"\\n--- Bot de Atendimento v1 (Sem Memória) ---\")\n",
    "    print(\"Assistente IA: Olá! Sou o assistente virtual da Empresa Y. Como posso ajudar?\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            entrada_usuario = input(\"Você: \")\n",
    "            if entrada_usuario.lower() in [\"sair\", \"tchau\", \"exit\"]:\n",
    "                print(\"Assistente IA: Entendido. Tenha um ótimo dia!\")\n",
    "                break\n",
    "            \n",
    "            contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "\n",
    "            resposta_ia = get_completion_from_messages(contexto, temperature=0.7) \n",
    "\n",
    "            if resposta_ia:\n",
    "                print(f\"Assistente IA: {resposta_ia}\")\n",
    "                \n",
    "                contexto.append({'role': 'assistant', 'content': resposta_ia})\n",
    "            else:\n",
    "                print(\"Assistente IA: Desculpe, tive um problema. Tente novamente.\")\n",
    "                contexto.pop()\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistente IA: Encerrando...\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_chat()\n",
    "\n",
    "# --- Lógica do Chat (ATUALIZADA PARA V3) ---\n",
    "def iniciar_chat():\n",
    "    contexto = [{'role': 'system', 'content': system_prompt_central_v2}]\n",
    "    \n",
    "    print(\"\\n--- Bot de Atendimento v3 (Salvando Leads) ---\")\n",
    "    print(\"Assistente IA: Olá! Sou o assistente virtual da Empresa Y. Como posso ajudar?\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            entrada_usuario = input(\"Você: \")\n",
    "            \n",
    "            # --- ATUALIZAÇÃO 1: Gatilho de Saída Inteligente ---\n",
    "            palavras_saida = [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\"]\n",
    "            \n",
    "            if any(palavra in entrada_usuario.lower() for palavra in palavras_saida):\n",
    "                print(\"Assistente IA: Entendido! Só um momento enquanto gero o resumo...\")\n",
    "\n",
    "                # --- ATUALIZAÇÃO 2: Meta-Tarefa (Extração de JSON) ---\n",
    "                # 1. Adiciona a última fala do usuário para contexto\n",
    "                contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "\n",
    "                # 2. O \"Meta-Prompt\" (A instrução secreta)\n",
    "                prompt_extracao = \"\"\"\n",
    "                Analise o histórico da conversa e extraia um JSON com:\n",
    "                1. intencao (VENDAS, SUPORTE, RH)\n",
    "                2. nome_cliente\n",
    "                3. email_cliente\n",
    "                4. resumo_solicitacao\n",
    "                Responda APENAS o JSON.\n",
    "                \"\"\"\n",
    "                # Injetamos o prompt no contexto temporariamente\n",
    "                contexto.append({'role': 'user', 'content': prompt_extracao})\n",
    "\n",
    "                # 3. Chama a IA em \"Modo JSON\" (temperature 0 para precisão)\n",
    "                resposta_json = get_completion_from_messages(\n",
    "                    contexto, \n",
    "                    json_mode=True, \n",
    "                    temperature=0\n",
    "                )\n",
    "                \n",
    "                # --- ATUALIZAÇÃO 3: Persistência (Salvar Arquivo) ---\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                nome_arquivo = f\"lead_{timestamp}.json\"\n",
    "                \n",
    "                try:\n",
    "                    with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "                        f.write(resposta_json)\n",
    "                    print(f\"\\n[SISTEMA]: Lead salvo com sucesso em '{nome_arquivo}'!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n[SISTEMA]: Erro ao salvar arquivo: {e}\")\n",
    "\n",
    "                break # Encerra o loop após salvar\n",
    "\n",
    "            # --- Lógica Normal de Conversa (Igual Aula 2) ---\n",
    "            contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "            resposta_ia = get_completion_from_messages(contexto, temperature=0.7) \n",
    "\n",
    "            if resposta_ia:\n",
    "                print(f\"Assistente IA: {resposta_ia}\")\n",
    "                contexto.append({'role': 'assistant', 'content': resposta_ia})\n",
    "            else:\n",
    "                print(\"Assistente IA: Desculpe, tive um problema. Tente novamente.\")\n",
    "                contexto.pop()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistente IA: Encerrando...\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "palavras_saida = [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\"]\n",
    "if any(palavra in entrada_usuario.lower() for palavra in palavras_saida):\n",
    "    print(\"Assistente IA: Entendido! Só um momento enquanto gero o resumo...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af98e765",
   "metadata": {},
   "source": [
    "1. O \"Gatilho Inteligente\" (Ouvindo a Despedida)\n",
    "\n",
    "O que é: Antes, só aceitávamos \"sair\". Agora, criamos uma lista (palavras_saida) com termos naturais que indicam o fim de uma conversa real, como \"ok\" ou \"obrigado\".\n",
    "\n",
    "A Lógica any(...): Essa função verifica se alguma dessas palavras está dentro da frase do usuário. Se o cliente disser \"Ah, ok, muito obrigado!\", o bot entende que acabou, mesmo que a frase seja longa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb83e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extracao = \"\"\"\n",
    "Analise o histórico da conversa e extraia um JSON com:\n",
    "1. intencao (VENDAS, SUPORTE, RH)\n",
    "2. nome_cliente\n",
    "3. email_cliente\n",
    "4. resumo_solicitacao\n",
    "Responda APENAS o JSON.\n",
    "\"\"\"\n",
    "contexto.append({'role': 'user', 'content': prompt_extracao})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177e6e5",
   "metadata": {},
   "source": [
    "2. O \"Meta-Prompt\" (A Instrução Oculta)\n",
    "\n",
    "O que é: Aqui acontece a mágica. O usuário já se despediu, mas o bot não desliga.\n",
    "\n",
    "A Ação: Nós injetamos uma nova mensagem no histórico (contexto.append) agindo como se fosse o usuário dizendo: \"Agora analise tudo o que falamos e me dê um resumo técnico\".\n",
    "\n",
    "Por que \"Meta-Prompt\"? Porque é um prompt sobre a conversa, não parte da conversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12df9f",
   "metadata": {},
   "source": [
    "    resposta_json = get_completion_from_messages(\n",
    "        contexto, \n",
    "        json_mode=True, \n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746dbe5",
   "metadata": {},
   "source": [
    "3. A Chamada Técnica (Modo JSON)\n",
    "\n",
    "json_mode=True: Esse parâmetro é crucial. Ele força o modelo gpt-4o-mini a retornar apenas um objeto JSON válido. Sem isso, a IA poderia responder \"Claro, aqui está o JSON: {...}\", o que quebraria nosso código de automação.\n",
    "\n",
    "temperature=0: Aqui não queremos criatividade. Queremos precisão cirúrgica na extração dos dados (nome e e-mail exatos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    nome_arquivo = f\"lead_{timestamp}.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "            f.write(resposta_json)\n",
    "        print(f\"\\n[SISTEMA]: Lead salvo com sucesso em '{nome_arquivo}'!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[SISTEMA]: Erro ao salvar arquivo: {e}\")\n",
    "\n",
    "    break # Encerra o loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. A Persistência (Salvando no Disco)\n",
    "\n",
    "O Nome Único: Usamos o datetime para gerar um carimbo de tempo (ex: 2025-11-12_10-30-05). Isso garante que cada conversa gere um arquivo novo (lead_DATA.json) e nunca sobrescreva o anterior.\n",
    "\n",
    "O Salvamento (with open...): O Python pega o texto que a IA gerou e escreve fisicamente no seu HD. É aqui que a memória RAM (volátil) vira memória de disco (permanente).\n",
    "\n",
    "break: Só depois de garantir que o arquivo está salvo é que permitimos o programa encerrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Script: central_atendimento_bot_v3.py\n",
    "# (Projeto Final da Aula 3 - Bot com Memória e Ação JSON)\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json      # <--- NOVO: Para lidar com formato JSON\n",
    "import datetime  # <--- NOVO: Para gerar o nome do arquivo com data/hora\n",
    "\n",
    "print(\"Carregando variáveis de ambiente...\")\n",
    "load_dotenv()\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Setup da API concluído.\")\n",
    "\n",
    "# --- Função Helper (Mantida igual) ---\n",
    "def get_completion_from_messages(messages, model=\"gpt-4o-mini\", json_mode=False, temperature=0.7):\n",
    "    try:\n",
    "        request_params = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "        }\n",
    "        if json_mode:\n",
    "            request_params[\"response_format\"] = {\"type\": \"json_object\"}\n",
    "        \n",
    "        response = client.chat.completions.create(**request_params)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao chamar a API: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Cérebro V2 (COMPLETO - Igual à Aula 2) ---\n",
    "system_prompt_central_v2 = \"\"\"\n",
    "Você é o Assistente Virtual da Empresa Y, a recepcionista inteligente.\n",
    "Seu objetivo é classificar a intenção inicial, iniciar a conversa corretamente\n",
    "e depois continuar de forma natural para coletar as informações necessárias.\n",
    "\n",
    "**FLUXO DA CONVERSA:**\n",
    "\n",
    "**1. Classificação Inicial (Primeira Mensagem do Usuário):**\n",
    "   - Analise a primeira mensagem e determine a intenção: 'VENDAS', 'SUPORTE', 'RH', ou 'DUVIDA'.\n",
    "\n",
    "**2. Primeira Resposta (Use APENAS uma destas):**\n",
    "   - Para 'VENDAS': \"Olá! Que ótimo seu interesse em nossos produtos/serviços.\n",
    "     Para direcionar você ao especialista certo, pode me dizer qual produto/serviço mais lhe interessa?\"\n",
    "   \n",
    "   - Para 'SUPORTE': \"Olá! Sinto muito que esteja tendo problemas.\n",
    "     Para que eu possa registrar seu caso e agilizar o atendimento, qual é o seu e-mail de cadastro conosco?\"\n",
    "   \n",
    "   - Para 'RH': \"Olá! Ficamos felizes com seu interesse em fazer parte da nossa equipe.\n",
    "     Você poderia, por favor, me informar para qual área ou vaga gostaria de se candidatar?\"\n",
    "   \n",
    "   - Para 'DUVIDA': \"Olá! Obrigado por entrar em contato. Para que eu possa te ajudar melhor,\n",
    "     você poderia me dizer se seu interesse é sobre nossos produtos (Vendas),\n",
    "     se precisa de ajuda com algo que já usa (Suporte) ou se é sobre oportunidades de trabalho (RH)?\"\n",
    "\n",
    "**3. Continuação da Conversa (APÓS a primeira resposta):**\n",
    "   - **Leia TODO o histórico da conversa (contexto).**\n",
    "   - Responda de forma **natural e conversacional**, ajudando o usuário a progredir dentro da intenção detectada.\n",
    "   - **Para VENDAS:** Após o usuário indicar o produto, faça perguntas para qualificar\n",
    "     (ex: \"Entendido! E qual seria a quantidade?\" ou \"Para qual tipo de uso você precisa?\").\n",
    "   - **Para SUPORTE:** Após obter o e-mail, peça detalhes do problema\n",
    "     (ex: \"Obrigado! Poderia descrever o erro que está ocorrendo?\").\n",
    "   - **Para RH:** Após saber a área/vaga, peça o CV ou LinkedIn\n",
    "     (ex: \"Ótimo! Você pode me enviar o link do seu perfil ou o currículo em anexo?\").\n",
    "   - Mantenha o tom amigável e prestativo.\n",
    "\"\"\"\n",
    "\n",
    "# --- Lógica do Chat (ATUALIZADA PARA V3) ---\n",
    "def iniciar_chat():\n",
    "    contexto = [{'role': 'system', 'content': system_prompt_central_v2}]\n",
    "    \n",
    "    print(\"\\n--- Bot de Atendimento v3 (Salvando Leads) ---\")\n",
    "    print(\"Assistente IA: Olá! Sou o assistente virtual da Empresa Y. Como posso ajudar?\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            entrada_usuario = input(\"Você: \")\n",
    "            \n",
    "            # --- ATUALIZAÇÃO 1: Gatilho de Saída Inteligente ---\n",
    "            palavras_saida = [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\", \"só isso\"]\n",
    "            \n",
    "            if any(palavra in entrada_usuario.lower() for palavra in palavras_saida):\n",
    "                print(\"Assistente IA: Entendido! Só um momento enquanto gero o resumo...\")\n",
    "\n",
    "                # --- ATUALIZAÇÃO 2: Meta-Tarefa (Extração de JSON) ---\n",
    "                # 1. Adiciona a última fala do usuário para contexto\n",
    "                contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "\n",
    "                # 2. O \"Meta-Prompt\" (A instrução secreta)\n",
    "                prompt_extracao = \"\"\"\n",
    "                Analise o histórico da conversa e extraia um JSON com:\n",
    "                1. intencao (VENDAS, SUPORTE, RH)\n",
    "                2. nome_cliente\n",
    "                3. email_cliente\n",
    "                4. resumo_solicitacao\n",
    "                Responda APENAS o JSON.\n",
    "                \"\"\"\n",
    "                # Injetamos o prompt no contexto temporariamente\n",
    "                contexto.append({'role': 'user', 'content': prompt_extracao})\n",
    "\n",
    "                # 3. Chama a IA em \"Modo JSON\" (temperature 0 para precisão)\n",
    "                resposta_json = get_completion_from_messages(\n",
    "                    contexto, \n",
    "                    json_mode=True, \n",
    "                    temperature=0\n",
    "                )\n",
    "                \n",
    "                # --- ATUALIZAÇÃO 3: Persistência (Salvar Arquivo) ---\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                nome_arquivo = f\"lead_{timestamp}.json\"\n",
    "                \n",
    "                try:\n",
    "                    with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "                        f.write(resposta_json)\n",
    "                    print(f\"\\n[SISTEMA]: Lead salvo com sucesso em '{nome_arquivo}'!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n[SISTEMA]: Erro ao salvar arquivo: {e}\")\n",
    "\n",
    "                break # Encerra o loop após salvar\n",
    "\n",
    "            # --- Lógica Normal de Conversa (Igual Aula 2) ---\n",
    "            contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "            resposta_ia = get_completion_from_messages(contexto, temperature=0.7) \n",
    "\n",
    "            if resposta_ia:\n",
    "                print(f\"Assistente IA: {resposta_ia}\")\n",
    "                contexto.append({'role': 'assistant', 'content': resposta_ia})\n",
    "            else:\n",
    "                print(\"Assistente IA: Desculpe, tive um problema. Tente novamente.\")\n",
    "                contexto.pop()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistente IA: Encerrando...\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d566d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iniciar_chat():\n",
    "    contexto = [{'role': 'system', 'content': system_prompt_central_v2}]\n",
    "    \n",
    "    print(\"\\n--- Bot de Atendimento v3 (Salvando Leads) ---\")\n",
    "    print(\"Assistente IA: Olá! Sou o assistente virtual da Empresa Manual de IA para DEVs. Como posso ajudar?\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            entrada_usuario = input(\"Você: \")\n",
    "\n",
    "            palavras_saida = [\"sair\", \"tchau\", \"exit\", \"ok\", \"obrigado\", \"pronto\", \"só isso\"]\n",
    "            \n",
    "            if any(palavra in entrada_usuario.lower() for palavra in palavras_saida):\n",
    "                print(\"Assistente IA: Entendido! Só um momento enquanto gero o resumo...\")\n",
    "\n",
    "                contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "\n",
    "                prompt_extracao = \"\"\"\n",
    "                Analise o histórico da conversa e extraia um JSON com:\n",
    "                1. intencao (VENDAS, SUPORTE, RH)\n",
    "                2. nome_cliente\n",
    "                3. email_cliente\n",
    "                4. resumo_solicitacao\n",
    "                Responda APENAS o JSON.\n",
    "                \"\"\"\n",
    "\n",
    "                contexto.append({'role': 'user', 'content': prompt_extracao})\n",
    "\n",
    "                resposta_json = get_completion_from_messages(\n",
    "                    contexto, \n",
    "                    json_mode=True, \n",
    "                    temperature=0\n",
    "                )\n",
    "                \n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "                nome_arquivo = f\"lead_{timestamp}.json\"\n",
    "                \n",
    "                try:\n",
    "                    with open(nome_arquivo, 'w', encoding='utf-8') as f:\n",
    "                        f.write(resposta_json)\n",
    "                    print(f\"\\n[SISTEMA]: Lead salvo com sucesso em '{nome_arquivo}'!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n[SISTEMA]: Erro ao salvar arquivo: {e}\")\n",
    "\n",
    "                break \n",
    "\n",
    "            contexto.append({'role': 'user', 'content': entrada_usuario})\n",
    "            resposta_ia = get_completion_from_messages(contexto, temperature=0.7) \n",
    "\n",
    "            if resposta_ia:\n",
    "                print(f\"Assistente IA: {resposta_ia}\")\n",
    "                contexto.append({'role': 'assistant', 'content': resposta_ia})\n",
    "            else:\n",
    "                print(\"Assistente IA: Desculpe, tive um problema. Tente novamente.\")\n",
    "                contexto.pop()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nAssistente IA: Encerrando...\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32dee79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af0fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
